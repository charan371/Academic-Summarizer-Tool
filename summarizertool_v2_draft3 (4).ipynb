{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLZz5p02Nxpj"
      },
      "outputs": [],
      "source": [
        "!pip install sentence-transformers faiss-cpu transformers feedparser streamlit\n",
        "!pip install langchain langchain-community langgraph\n",
        "!pip install crewai\n",
        "!pip install --upgrade gradio\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import pipeline\n",
        "import gradio as gr\n",
        "import os\n",
        "import sys\n",
        "from langgraph.graph import StateGraph\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
        "from crewai import Agent, Task, Crew\n",
        "from crewai.tools import BaseTool\n",
        "from pydantic import BaseModel, Field\n"
      ],
      "metadata": {
        "id": "lexRl8DUQ7ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MCPServer:\n",
        "    def __init__(self):\n",
        "        self.context_history = []\n",
        "\n",
        "    def save_context(self, query, summary, recommendations):\n",
        "        self.context_history.append({\n",
        "            \"query\": query,\n",
        "            \"summary\": summary,\n",
        "            \"recommendations\": recommendations\n",
        "        })\n",
        "\n",
        "    def get_latest(self):\n",
        "        return self.context_history[-1] if self.context_history else None\n",
        "\n",
        "# Global server object\n",
        "mcp_server = MCPServer()"
      ],
      "metadata": {
        "id": "yEBq8PX6rxjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import feedparser\n",
        "from urllib.parse import quote\n",
        "\n",
        "def search_arxiv(query, max_results=20):\n",
        "    base_url = 'http://export.arxiv.org/api/query?'\n",
        "    search_query = f'search_query=all:{quote(query)}&start=0&max_results={max_results}'\n",
        "    feed = feedparser.parse(base_url + search_query)\n",
        "    return feed.entries\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "h5JmdNqSSCSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Keep domain structure as is\n",
        "domain_structure = {\n",
        "    \"Artificial Intelligence\": [\n",
        "        \"Machine Learning\", \"Deep Learning\", \"Reinforcement Learning\", \"Transfer Learning\",\n",
        "        \"Self-Supervised Learning\", \"Meta-Learning\", \"Federated Learning\", \"Explainable AI\",\n",
        "        \"Generative AI\", \"AI Ethics\"\n",
        "    ],\n",
        "    \"Healthcare & Biomedical AI\": [\n",
        "        \"Medical Imaging\", \"Clinical NLP\", \"Drug Discovery\", \"Disease Diagnosis Models\",\n",
        "        \"Predictive Healthcare\", \"Public Health Analytics\", \"Electronic Health Records\", \"Wearable Health Devices\",\n",
        "        \"Mental Health AI\", \"COVID-19 Research\"\n",
        "    ],\n",
        "    \"Finance & Economics\": [\n",
        "        \"Stock Price Prediction\", \"Fraud Detection\", \"Algorithmic Trading\", \"Credit Risk Modeling\",\n",
        "        \"Financial Sentiment Analysis\", \"AI in Insurance\", \"Economic Forecasting\", \"Portfolio Optimization\",\n",
        "        \"Blockchain & Crypto Analytics\", \"Regulatory Technology\"\n",
        "    ],\n",
        "    \"Law & Policy\": [\n",
        "        \"Legal Document Summarization\", \"AI in Legal Reasoning\", \"Contract Analysis & NLP\", \"Legal QA\",\n",
        "        \"Case Law Retrieval\", \"Judgment Prediction\", \"Legal Chatbots\", \"Privacy Law Compliance\",\n",
        "        \"Policy Modeling\", \"AI in Legal Reasoning\"\n",
        "    ],\n",
        "    \"Education & Social Science\": [\n",
        "        \"Intelligent Tutoring Systems\", \"AI in Education\", \"Student Performance Prediction\", \"Academic Plagiarism Detection\",\n",
        "        \"Exam Question Generation\", \"Adaptive Learning\", \"Education Data Mining\", \"Misinformation in EdTech\",\n",
        "        \"Educational NLP\", \"Conversational Agents in Education\"\n",
        "    ],\n",
        "    \"Sustainability, Industry & Robotics\": [\n",
        "        \"Climate Modeling\", \"Renewable Energy\", \"Smart Grids\", \"AI in Agriculture\",\n",
        "        \"Precision Farming\", \"Autonomous Vehicles\", \"Robotics and Automation\", \"Predictive Maintenance\",\n",
        "        \"Industrial Automation\", \"Disaster Response\"\n",
        "    ]\n",
        "}"
      ],
      "metadata": {
        "id": "O6kDgvyEwA4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# New function: fetch papers and summarize using MCP tools\n",
        "#def fetch_and_summarize_papers(domain_structure, max_results=20):\n",
        "    #all_papers = []\n",
        "    #for domain, subdomains in domain_structure.items():\n",
        "        #for sub in subdomains:\n",
        "#             print(f\"🔍 Fetching papers for: {domain} → {sub}\")\n",
        "\n",
        "#             # Use arxiv_tool to fetch papers\n",
        "#             papers = arxiv_tool.run(sub)\n",
        "\n",
        "#             for paper in papers:\n",
        "#                 abstract_text = paper.get(\"summary\", \"\")\n",
        "#                 if abstract_text:\n",
        "#                     # Use summarizer_tool to summarize abstract\n",
        "#                     summarized = summarizer_tool.run(abstract_text)\n",
        "#                 else:\n",
        "#                     summarized = \"No abstract available\"\n",
        "\n",
        "#                 paper['summary'] = summarized\n",
        "#                 paper['domain'] = domain\n",
        "#                 paper['subdomain'] = sub\n",
        "#             all_papers.extend(papers)\n",
        "\n",
        "#     df_all = pd.DataFrame(all_papers)\n",
        "#     return df_all\n",
        "\n",
        "\n",
        "\n",
        "# df_all = fetch_and_summarize_papers(domain_structure)\n",
        "# df_all.to_csv(\"arxiv_1200_papers.csv\", index=False)\n",
        "# print(\"✅ Papers fetched, summarized, and saved to CSV!\")"
      ],
      "metadata": {
        "id": "BhFlDOtHRsMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Check paper counts per subdomain (optional - uncomment when needed)\n",
        "# if 'df_all' in globals():\n",
        "#     subdomain_counts = df_all.groupby(['domain', 'subdomain']).size().reset_index(name='num_papers')\n",
        "#     print(subdomain_counts.sort_values('num_papers'))\n",
        "# else:\n",
        "#     print(\"⚠️ Dataframe 'df_all' not loaded yet. Run fetch_and_summarize_papers() or load CSV first.\")\n"
      ],
      "metadata": {
        "id": "VlUBh2IMzpjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset if previously saved\n",
        "df_loaded = pd.read_csv('arxiv_1200_papers (2).csv')\n",
        "print(f\"✅ Loaded CSV with {df_loaded.shape[0]} papers.\")\n",
        "display(df_loaded.head())"
      ],
      "metadata": {
        "id": "F53IARUiSmue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load embedding model (already used in previous block but kept here if re-run separately)\n",
        "embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "print(\"✅ Embedding model loaded!\")\n",
        "\n",
        "# Define MCP Tool for embedding if not already defined\n",
        "def embed_text(text):\n",
        "    \"\"\"Embed a single text string into a vector.\"\"\"\n",
        "    return embed_model.encode([text]).tolist()\n",
        "\n",
        "# Build FAISS index using abstracts\n",
        "abstract_texts = df_loaded['summary'].fillna(\"\").tolist()\n",
        "abstract_embeddings = embed_model.encode(abstract_texts, show_progress_bar=True)\n",
        "abstract_embeddings = np.array(abstract_embeddings).astype('float32')\n",
        "\n",
        "dimension = abstract_embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(abstract_embeddings)\n",
        "print(f\"✅ FAISS index created with {index.ntotal} papers!\")\n"
      ],
      "metadata": {
        "id": "8n5UZWRLSM50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=\"manjunathainti/fine_tuned_t5_summarizer\")\n",
        "print(\"✅ Summarizer model loaded!\")\n",
        "\n",
        "def summarize_text(text: str) -> str:\n",
        "    return summarizer(text, max_length=200, min_length=50, do_sample=False)[0][\"summary_text\"]\n",
        "\n",
        "# For long input with dynamic chunking logic\n",
        "def summarize_input_text(text: str) -> str:\n",
        "    text = text.strip().replace(\"\\n\", \" \")\n",
        "    word_count = len(text.split())\n",
        "\n",
        "    if word_count < 50:\n",
        "        return summarize_text(text)\n",
        "\n",
        "    # Break into roughly ~300 word chunks\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "    for word in text.split():\n",
        "        current_chunk.append(word)\n",
        "        if len(current_chunk) >= 300:\n",
        "            chunks.append(\" \".join(current_chunk))\n",
        "            current_chunk = []\n",
        "    if current_chunk:\n",
        "        chunks.append(\" \".join(current_chunk))\n",
        "\n",
        "    # Summarize each chunk individually\n",
        "    summaries = []\n",
        "    for chunk in chunks:\n",
        "        summary = summarizer(chunk, max_length=200, min_length=50, do_sample=False)[0][\"summary_text\"]\n",
        "        summaries.append(summary)\n",
        "\n",
        "    return \"\\n\".join(summaries)"
      ],
      "metadata": {
        "id": "9dpGdbuiTAyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_related_papers(user_input, top_k=5, domain_filter=\"All\", subdomain_filter=\"All\"):\n",
        "    # Search FAISS index on the entire dataset\n",
        "    user_vec = embed_model.encode([user_input]).astype('float32')\n",
        "    D, I = index.search(user_vec, 50)  # fetch more than top_k initially\n",
        "\n",
        "    results = []\n",
        "    for idx, dist in zip(I[0], D[0]):\n",
        "        if idx >= len(df_loaded):\n",
        "            continue\n",
        "\n",
        "        paper = df_loaded.iloc[idx].to_dict()\n",
        "\n",
        "        # Apply filters AFTER search\n",
        "        if domain_filter != \"All\" and paper['domain'] != domain_filter:\n",
        "            continue\n",
        "        if subdomain_filter != \"All\" and paper['subdomain'] != subdomain_filter:\n",
        "            continue\n",
        "\n",
        "        doc_vec = embed_model.encode([paper['abstract']]).astype('float32')\n",
        "        user_norm = user_vec / np.linalg.norm(user_vec)\n",
        "        doc_norm = doc_vec / np.linalg.norm(doc_vec)\n",
        "        cos_sim = float(np.dot(user_norm, doc_norm.T))\n",
        "        cos_sim = min(max(cos_sim, 0.0), 1.0)  # Clip for safety\n",
        "        paper['similarity_score'] = round(cos_sim, 3)\n",
        "        results.append(paper)\n",
        "\n",
        "    results = sorted(results, key=lambda x: x['similarity_score'], reverse=True)\n",
        "\n",
        "    # ✅ Return only top_k\n",
        "    return results[:top_k]"
      ],
      "metadata": {
        "id": "eBYFPIXlURE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from crewai.tools import BaseTool\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "hf_tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n",
        "hf_model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\")\n",
        "hf_pipeline = pipeline(\"text2text-generation\", model=hf_model, tokenizer=hf_tokenizer)\n",
        "\n",
        "hf_llm = HuggingFacePipeline(pipeline=hf_pipeline)\n",
        "\n",
        "def summarize_text_tool(text: str) -> str:\n",
        "    \"\"\"Summarizes academic input using chunking if needed.\"\"\"\n",
        "    if len(text.split()) < 100:\n",
        "        return summarize_text(text)\n",
        "    else:\n",
        "        return summarize_input_text(text)\n",
        "\n",
        "class SummarizerTool(BaseTool):\n",
        "    name: str = \"summarizer_tool\"\n",
        "    description: str = \"Summarizes academic input.\"\n",
        "\n",
        "    def _run(self, text: str):\n",
        "        return summarize_text_tool(text)\n",
        "\n",
        "summarizer_tool_instance = SummarizerTool()\n",
        "\n",
        "def embed_text_tool(text: str) -> list:\n",
        "    \"\"\"Encodes input text into embedding vector.\"\"\"\n",
        "    return embed_model.encode([text]).tolist()\n",
        "\n",
        "class EmbedderTool(BaseTool):\n",
        "    name: str = \"embedder_tool\"\n",
        "    description: str = \"Embeds academic input into a vector representation.\"\n",
        "\n",
        "    def _run(self, text: str):\n",
        "        return embed_text_tool(text)\n",
        "\n",
        "embedder_tool_instance = EmbedderTool()\n",
        "\n",
        "class RecommenderToolArgs(BaseModel):\n",
        "    user_input: str = Field(..., description=\"User query for finding related papers\")\n",
        "    top_k: int = Field(5, description=\"Number of papers to return\")\n",
        "    domain_filter: str = Field(\"All\", description=\"Domain to filter papers\")\n",
        "    subdomain_filter: str = Field(\"All\", description=\"Subdomain to filter papers\")\n",
        "\n",
        "class RecommenderTool(BaseTool):\n",
        "    name: str = \"recommender_tool\"\n",
        "    description: str = \"Recommends related papers with similarity scores and metadata\"\n",
        "    args_schema = RecommenderToolArgs\n",
        "\n",
        "    def _run(self, user_input, top_k=5, domain_filter=\"All\", subdomain_filter=\"All\"):\n",
        "        return find_related_papers(user_input, top_k, domain_filter, subdomain_filter)\n",
        "\n",
        "\n",
        "# Instantiate\n",
        "recommender_tool_instance = RecommenderTool()\n",
        "\n",
        "summarizer_agent = Agent(\n",
        "    role=\"Academic Summarizer\",\n",
        "    goal=\"Summarize academic research clearly and concisely.\",\n",
        "    backstory=\"An NLP agent trained to digest research papers.\",\n",
        "    verbose=True,\n",
        "    tools=[summarizer_tool_instance], # Pass the tool instance\n",
        "    llm=hf_llm\n",
        "\n",
        ")\n",
        "\n",
        "embedder_agent = Agent(\n",
        "    role=\"Embedding Generator\",\n",
        "    goal=\"Convert academic abstracts into meaningful vector representations.\",\n",
        "    backstory=\"A specialist agent trained to map academic language to dense vector spaces for similarity search.\",\n",
        "    verbose=True,\n",
        "    tools=[embedder_tool_instance],\n",
        "    llm=hf_llm\n",
        ")\n",
        "\n",
        "recommender_agent = Agent(\n",
        "    role=\"Paper Recommender\",\n",
        "    goal=\"Find top 5 academic papers based on input relevance.\",\n",
        "    backstory=\"Specialist in vector similarity and embeddings.\",\n",
        "    verbose=True,\n",
        "    tools=[recommender_tool_instance],\n",
        "    llm=hf_llm\n",
        ")"
      ],
      "metadata": {
        "id": "BXv9snIV86wD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define tasks\n",
        "summarizer_task = Task(\n",
        "    description=\"Summarize the following academic abstract: {input_text}\",\n",
        "    expected_output=\"A concise summary.\",\n",
        "    agent=summarizer_agent\n",
        ")\n",
        "\n",
        "embedder_task = Task(\n",
        "    description=\"Generate an embedding vector for the input text: {input_text}\",\n",
        "    expected_output=\"A vector representation of the input.\",\n",
        "    agent=embedder_agent\n",
        ")\n",
        "\n",
        "recommender_task = Task(\n",
        "    description=\"Recommend 5 relevant papers for: {input_text}\",\n",
        "    expected_output=\"A list of paper titles.\",\n",
        "    agent=recommender_agent\n",
        ")\n",
        "\n",
        "# Multi-agent crew for combined task\n",
        "combined_crew = Crew(\n",
        "    agents=[summarizer_agent, embedder_agent, recommender_agent],\n",
        "    tasks=[summarizer_task, embedder_task, recommender_task],\n",
        "    verbose=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "RH6th4E_891M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load zero-shot classification pipeline\n",
        "classifier = pipeline(\n",
        "    \"zero-shot-classification\",\n",
        "    model=\"t5-base\"\n",
        ")\n",
        "print(\" Zero-shot classifier loaded!\")\n",
        "candidate_labels = [\n",
        "    # AI\n",
        "    \"Machine Learning\", \"Deep Learning\", \"Reinforcement Learning\", \"Transfer Learning\",\n",
        "    \"Self-Supervised Learning\", \"Meta-Learning\", \"Federated Learning\", \"Explainable AI\",\n",
        "    \"Generative AI\", \"AI Ethics\",\n",
        "\n",
        "    # Healthcare\n",
        "    \"Medical Imaging\", \"Clinical NLP\", \"Drug Discovery\", \"Disease Diagnosis Models\",\n",
        "    \"Predictive Healthcare\", \"Public Health Analytics\", \"Electronic Health Records\",\n",
        "    \"Wearable Health Devices\", \"Mental Health AI\", \"COVID-19 Research\",\n",
        "\n",
        "    # Finance\n",
        "    \"Stock Price Prediction\", \"Fraud Detection\", \"Algorithmic Trading\", \"Credit Risk Modeling\",\n",
        "    \"Financial Sentiment Analysis\", \"AI in Insurance\", \"Economic Forecasting\",\n",
        "    \"Portfolio Optimization\", \"Blockchain & Crypto Analytics\", \"Regulatory Technology\",\n",
        "\n",
        "    # Law\n",
        "    \"Legal Document Summarization\", \"AI in Legal Reasoning\", \"Contract Analysis & NLP\",\n",
        "    \"Legal QA\", \"Case Law Retrieval\", \"Judgment Prediction\", \"Legal Chatbots\",\n",
        "    \"Privacy Law Compliance\", \"Policy Modeling\",\n",
        "\n",
        "    # Education\n",
        "    \"Intelligent Tutoring Systems\", \"AI in Education\", \"Student Performance Prediction\",\n",
        "    \"Academic Plagiarism Detection\", \"Exam Question Generation\", \"Adaptive Learning\",\n",
        "    \"Education Data Mining\", \"Misinformation in EdTech\", \"Educational NLP\",\n",
        "    \"Conversational Agents in Education\",\n",
        "\n",
        "    # Sustainability & Robotics\n",
        "    \"Climate Modeling\", \"Renewable Energy\", \"Smart Grids\", \"AI in Agriculture\",\n",
        "    \"Precision Farming\", \"Autonomous Vehicles\", \"Robotics & Control\",\n",
        "    \"Predictive Maintenance\", \"Industrial Automation\", \"Disaster Response\"\n",
        "]\n",
        "\n",
        "# Define classification function\n",
        "def classify_domain(abstract):\n",
        "    result = classifier(abstract, candidate_labels)\n",
        "    return result['labels'][0]\n"
      ],
      "metadata": {
        "id": "OALFZlu_TxH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_csv(recommendations):\n",
        "    \"\"\"\n",
        "    Save recommended papers to CSV.\n",
        "    Now recommendations is a list of dicts (from find_related_papers) not a DataFrame.\n",
        "    \"\"\"\n",
        "    if isinstance(recommendations, list):\n",
        "        df_out = pd.DataFrame(recommendations)\n",
        "    else:\n",
        "        df_out = recommendations\n",
        "\n",
        "    # Check if similarity_score exists in recommendations\n",
        "    columns_to_save = ['title', 'summary', 'link', 'domain', 'subdomain']\n",
        "    if 'similarity_score' in df_out.columns:\n",
        "        columns_to_save.append('similarity_score')\n",
        "\n",
        "    df_out = df_out[columns_to_save]\n",
        "    df_out.to_csv(\"recommendations.csv\", index=False)\n",
        "    return \"recommendations.csv\""
      ],
      "metadata": {
        "id": "Cxnoe9Rn_c9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_csv_wrapper(user_input, domain, subdomain, task_choice):\n",
        "    domain_filter = domain if domain and domain.strip() != \"\" else \"All\"\n",
        "    subdomain_filter = subdomain if subdomain and subdomain.strip() != \"\" else \"All\"\n",
        "\n",
        "    recommendations = recommender_tool_instance._run(\n",
        "        user_input=user_input,\n",
        "        top_k=5,\n",
        "        domain_filter=domain_filter,\n",
        "        subdomain_filter=subdomain_filter\n",
        "    )\n",
        "\n",
        "    return generate_csv(recommendations)\n"
      ],
      "metadata": {
        "id": "V0JrmbCMXDUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your input text (replace with anything you want to test)\n",
        "user_input_text = \"\"\"\n",
        "Federated Learning (FL) has emerged as a promising distributed machine learning paradigm that enables collaborative model training across multiple devices or institutions without sharing raw data. This approach preserves data privacy by transmitting only model updates, which are aggregated centrally to form a global model. By keeping data localized, FL addresses critical concerns about data ownership, confidentiality, and compliance with regulations such as GDPR and HIPAA. This makes it especially valuable in domains like healthcare, finance, and mobile applications where data sensitivity is paramount.\n",
        "\n",
        "One of the key strengths of FL lies in its ability to leverage heterogeneous and decentralized data sources. Traditional centralized approaches often fail to capture the diversity inherent in real-world datasets, whereas FL can combine knowledge from varied distributions across clients. Techniques such as federated averaging (FedAvg) and secure aggregation have become foundational to address communication efficiency and privacy. However, challenges such as non-independent and identically distributed (non-IID) data, limited bandwidth, and varying client participation still pose significant obstacles to robust model performance.\n",
        "\n",
        "Recent advances have focused on enhancing FL’s scalability and resilience. Personalization strategies aim to balance the global model’s performance with each client’s specific data distribution, while adaptive communication protocols reduce overhead in large-scale deployments. Additionally, integrating differential privacy and homomorphic encryption into FL pipelines has further strengthened the security guarantees of model updates. These developments demonstrate FL’s growing potential to serve as a practical framework for real-world distributed AI systems.\n",
        "\n",
        "Despite its promise, FL remains an active area of research. Addressing fairness across clients, mitigating biases from skewed data distributions, and improving convergence speed are open challenges. Moreover, as FL expands into multimodal learning and cross-silo collaborations, designing algorithms that handle diverse data modalities and institutional requirements will be crucial. With continued innovation, Federated Learning could become a foundational building block for privacy-preserving and decentralized artificial intelligence.\n",
        "\n",
        "\"\"\"\n",
        "print(\" USER INPUT TEXT\")\n",
        "print(user_input_text)\n",
        "print(\"\\n==============================\\n\")\n",
        "\n",
        "# 1. Summarize input using the summarizer tool\n",
        "user_summary = summarizer_tool_instance._run(user_input_text)\n",
        "print(\" SUMMARIZED INPUT\")\n",
        "print(user_summary)\n",
        "print(\"\\n==============================\\n\")\n",
        "\n",
        "# 2. Get recommendations using the recommender tool (full metadata)\n",
        "recommendations = recommender_tool_instance._run(user_input_text)\n",
        "\n",
        "print(\" RECOMMENDED PAPERS\")\n",
        "for rec in recommendations:\n",
        "    print(f\"- Title: {rec.get('title', 'N/A')}\")\n",
        "\n",
        "    # Authors\n",
        "    if 'authors' in rec and rec['authors']:\n",
        "      authors = rec['authors']\n",
        "\n",
        "    # Handle different formats: string, list of strings, or list of dicts\n",
        "      if isinstance(authors, str):\n",
        "        try:\n",
        "            authors = eval(authors) if authors.startswith(\"[\") else [authors]\n",
        "        except:\n",
        "            authors = [authors]\n",
        "\n",
        "      if isinstance(authors, list):\n",
        "        processed_authors = []\n",
        "        for a in authors:\n",
        "            if isinstance(a, dict) and 'name' in a:  # list of dicts\n",
        "                processed_authors.append(a['name'])\n",
        "            elif isinstance(a, str):  # list of strings\n",
        "                processed_authors.append(a)\n",
        "            else:\n",
        "                processed_authors.append(str(a))  # fallback\n",
        "\n",
        "        if processed_authors:\n",
        "            print(f\"  Authors: {', '.join(processed_authors)}\")\n",
        "\n",
        "\n",
        "    # Domain\n",
        "    print(f\"  Domain: {rec.get('domain', 'N/A')}\")\n",
        "\n",
        "    # Published\n",
        "    if 'published' in rec:\n",
        "        print(f\"  Published: {rec.get('published', 'N/A')}\")\n",
        "\n",
        "    # Link\n",
        "    if 'link' in rec:\n",
        "        print(f\"  Link: {rec.get('link', '#')}\")\n",
        "\n",
        "    # Similarity Score\n",
        "    if 'similarity_score' in rec:\n",
        "        print(f\"  Similarity Score: {rec.get('similarity_score', 0):.2f}\")\n",
        "\n",
        "    print(f\"  Summary: {rec.get('summary', 'No summary available')}\")\n",
        "    print(\"--------------------------------\")\n"
      ],
      "metadata": {
        "id": "vBrOh7tAZey6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_apa_citation(title, authors, published, link):\n",
        "    # Handle year extraction\n",
        "    try:\n",
        "        year = published.split(\"-\")[0]\n",
        "    except:\n",
        "        year = \"n.d.\"\n",
        "\n",
        "    # Normalize authors into a list of names\n",
        "    authors_list = []\n",
        "\n",
        "    # Handle if authors is a string\n",
        "    if isinstance(authors, str):\n",
        "        try:\n",
        "            parsed_authors = eval(authors) if authors.strip().startswith(\"[\") else [authors]\n",
        "        except:\n",
        "            parsed_authors = [authors]\n",
        "    else:\n",
        "        parsed_authors = authors\n",
        "\n",
        "    # Handle if authors is a list of dicts or list of strings\n",
        "    if isinstance(parsed_authors, list):\n",
        "        for a in parsed_authors:\n",
        "            if isinstance(a, dict) and \"name\" in a:  # dict format\n",
        "                authors_list.append(a[\"name\"])\n",
        "            elif isinstance(a, str):\n",
        "                authors_list.append(a)\n",
        "            else:\n",
        "                authors_list.append(str(a))  # fallback\n",
        "    else:\n",
        "        authors_list.append(str(parsed_authors))\n",
        "\n",
        "    # Format APA author string\n",
        "    author_str = \", \".join(authors_list[:3])\n",
        "    if len(authors_list) > 3:\n",
        "        author_str += \", et al.\"\n",
        "\n",
        "    # Final APA-style string\n",
        "    return f\"{author_str} ({year}). <i>{title}</i>.<br>Retrieved from <a href='{link}' target='_blank'>{link}</a>\"\n",
        "\n"
      ],
      "metadata": {
        "id": "CUGtGvTbBG7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import sys\n",
        "try:\n",
        "    import absl.logging\n",
        "    from unittest.mock import MagicMock\n",
        "\n",
        "    def safe_close(self):\n",
        "        try:\n",
        "            if hasattr(self.stream, 'close'):\n",
        "                self.stream.close()\n",
        "        except Exception:\n",
        "            pass\n",
        "    absl.logging.PythonHandler.close = safe_close\n",
        "except ImportError:\n",
        "    pass\n",
        "\n",
        "for name in ['uvicorn', 'uvicorn.access', 'uvicorn.error', 'uvicorn.asgi', 'httpx', 'httpcore', 'asyncio', 'websockets']:\n",
        "    logger = logging.getLogger(name)\n",
        "    logger.disabled = True\n",
        "    logger.propagate = False\n",
        "    for handler in logger.handlers[:]:\n",
        "        logger.removeHandler(handler)\n",
        "\n",
        "logging.basicConfig(stream=sys.stderr, level=logging.ERROR, force=True)\n"
      ],
      "metadata": {
        "id": "9-MOMCjxcBqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def update_subdomains(domain):\n",
        "    \"\"\"Update subdomain dropdown based on selected domain.\"\"\"\n",
        "    if domain in domain_structure:\n",
        "        return gr.update(choices=[\"All\"] + domain_structure[domain], value=\"All\")\n",
        "    return gr.update(choices=[], value=None)\n",
        "\n",
        "def run_agent_ui(user_input, domain, subdomain, task):\n",
        "    if not user_input.strip():\n",
        "        return \"⚠️ Please enter an abstract.\", \"<p style='color:red;'>No papers found.</p>\"\n",
        "\n",
        "    # Handle filters\n",
        "    domain_filter = domain if domain and domain.strip() != \"\" else \"All\"\n",
        "    subdomain_filter = subdomain if subdomain and subdomain.strip() != \"\" else \"All\"\n",
        "\n",
        "    summary = \"\"\n",
        "    recommendations = []\n",
        "\n",
        "    try:\n",
        "        # 🟢 Only Summarize\n",
        "        if task == \"Summarize\":\n",
        "          summary = summarizer_tool_instance._run(user_input)\n",
        "          recommendations_html = \"📄 Only summarizer will run. Recommender not requested.\"\n",
        "          return summary, recommendations_html\n",
        "\n",
        "        elif task == \"Recommend Papers\":\n",
        "          summary = \"📚 Only recommender will run. Summary not requested.\"\n",
        "          recommendations = recommender_tool_instance._run(\n",
        "            user_input=user_input,\n",
        "            top_k=5,\n",
        "            domain_filter=domain_filter,\n",
        "            subdomain_filter=subdomain_filter\n",
        "          )\n",
        "\n",
        "        elif task == \"Summarize + Recommend Papers\":\n",
        "          summary = summarizer_tool_instance._run(user_input)\n",
        "          recommendations = recommender_tool_instance._run(\n",
        "            user_input=user_input,\n",
        "            top_k=5,\n",
        "            domain_filter=domain_filter,\n",
        "            subdomain_filter=subdomain_filter\n",
        "          )\n",
        "\n",
        "\n",
        "        # 🧠 Format recommended papers\n",
        "        if not recommendations:\n",
        "            return summary, \"<p>No recommended papers found for this input.</p>\"\n",
        "\n",
        "        papers_html = \"<h3>Recommended Papers</h3>\"\n",
        "        for rec in recommendations:\n",
        "            try:\n",
        "                apa = format_apa_citation(\n",
        "                    rec.get('title', 'N/A'),\n",
        "                    rec.get('authors', []),\n",
        "                    rec.get('published', 'n.d.'),\n",
        "                    rec.get('link', '#')\n",
        "                )\n",
        "            except Exception as apa_error:\n",
        "                apa = f\"APA citation error: {str(apa_error)}\"\n",
        "\n",
        "            papers_html += f\"\"\"\n",
        "            <div style=\"margin-bottom: 15px; padding: 10px; border: 1px solid #ddd; border-radius: 5px;\">\n",
        "                <b>Title:</b> {rec.get('title', 'N/A')}<br>\n",
        "                <b>Authors:</b> {\", \".join(eval(rec['authors'])) if isinstance(rec.get('authors'), str) and rec['authors'].startswith(\"[\") else rec.get('authors', 'N/A')}<br>\n",
        "                <b>Domain:</b> {rec.get('domain', 'N/A')}<br>\n",
        "                <b>Subdomain:</b> {rec.get('subdomain', 'N/A')}<br>\n",
        "                <b>Published:</b> {rec.get('published', 'N/A')}<br>\n",
        "                <b>Link:</b> <a href=\"{rec.get('link', '#')}\" target=\"_blank\">View Paper</a><br>\n",
        "                <b>Similarity Score:</b> {rec.get('similarity_score', 0):.2f}<br>\n",
        "                <b>Summary:</b> {rec.get('summary', 'No summary available')}<br><br>\n",
        "\n",
        "                <details>\n",
        "                    <summary><b>Show APA Citation</b></summary>\n",
        "                    {apa}\n",
        "                </details>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "\n",
        "        return summary, papers_html\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"❌ Error processing request: {str(e)}\"\n",
        "        return error_msg, error_msg\n",
        "\n",
        "# Build the Gradio Interface\n",
        "with gr.Blocks(title=\"🧠 Summarizer + Recommender Agent\") as demo:\n",
        "    gr.Markdown(\"## 🧠 Summarizer + Recommender Agent\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            user_input = gr.Textbox(label=\"Input Abstract\", lines=8, placeholder=\"Paste abstract here...\")\n",
        "            domain = gr.Dropdown(choices=[\"All\"] + list(domain_structure.keys()), label=\"Domain (Optional)\", value=None)\n",
        "            subdomain = gr.Dropdown(choices=[], label=\"Subdomain (Optional)\", value=None)\n",
        "\n",
        "            # Dynamic update of subdomains\n",
        "            domain.change(fn=update_subdomains, inputs=domain, outputs=subdomain)\n",
        "\n",
        "            task_choice = gr.Dropdown(\n",
        "              choices=[\"Summarize\", \"Recommend Papers\", \"Summarize + Recommend Papers\"],\n",
        "              label=\"Select Task\",\n",
        "              value=None\n",
        "            )\n",
        "\n",
        "            submit_btn = gr.Button(\"▶️ Start Agent\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column():\n",
        "            summary_output = gr.Textbox(label=\"Summary of Input Abstract\", lines=6)\n",
        "            recommendations_output = gr.HTML(label=\"Recommended Papers\")\n",
        "            download_btn = gr.Button(\"📥 Download Recommended Papers as CSV\")\n",
        "\n",
        "\n",
        "    # Connect button\n",
        "    submit_btn.click(fn=run_agent_ui,\n",
        "                     inputs=[user_input, domain, subdomain, task_choice],\n",
        "                     outputs=[summary_output, recommendations_output])\n",
        "\n",
        "    download_btn.click(\n",
        "      fn=generate_csv_wrapper,\n",
        "      inputs=[user_input, domain, subdomain, task_choice],\n",
        "      outputs=gr.File(label=\"Download Recommendations CSV\")\n",
        "    )\n",
        "\n",
        "\n",
        "def run_gradio_safe():\n",
        "    print(\"🚀 Starting Gradio safely for Colab...\")\n",
        "    try:\n",
        "        import os\n",
        "        os.environ[\"GRADIO_SERVER_NAME\"] = \"0.0.0.0\"\n",
        "        logging.getLogger().handlers.clear()\n",
        "        demo.launch(share=True, show_error=True)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Gradio launch failed: {e}\")\n",
        "run_gradio_safe()"
      ],
      "metadata": {
        "id": "2OawY84qo5lq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}